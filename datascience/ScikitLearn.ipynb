{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando um dataset padrão\n",
    "O dataset iris é um dataset padrão de aprendizado de máquina, presente na biblioteca Scikit Learn para fácil inclusão.\n",
    "\n",
    "O dataset consiste de três tipos da flor iris, com atributos de cada tipo como cumprimento das pétalas.\n",
    "\n",
    "Para mais informações, visite http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html e https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Colocamos os atributos na variável 'X', e as classes na variável 'y'\n",
    "iris = sklearn.datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Na próxima linha, separamos os dados em dois conjuntos, treino e teste.\n",
    "# O treino será utilizado para construir o modelo de classificação, e o teste será utilizado para avaliá-lo.\n",
    "X_treino, X_teste, y_treino, y_teste = sklearn.cross_validation.train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino\n",
    "\n",
    "Agora, construiremos um modelo utilizando os dados de treino. A construção do modelo faz parte da fase de *Representação*, como comentamos nas aulas. Também faz parte desta fase a escolha e transformação dos atributos, ou *feature engineering*. Neste exemplo, iremos utilizar os atributos padrão do dataset iris.\n",
    "\n",
    "Para este exemplo, utilizaremos o modelo Regressão Logística para a classificação (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "# Nesta linha, utilizamos o treino para construir o modelo com a chamada 'fit'\n",
    "classificador.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste\n",
    "Com a nossa representação construída, podemos passar para a próxima fase, a de *Avaliação*.\n",
    "\n",
    "Primeiro, geramos as predições para os dados de teste, utilizando o modelo construído, e depos avaliamos os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Com o modelo treinado, podemos gerar nossas predições para os dados de teste, 'y_pred'\n",
    "y_pred = classificador.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.69      0.81        16\n",
      "          2       0.64      1.00      0.78         9\n",
      "\n",
      "avg / total       0.92      0.87      0.87        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agora, podemos comparar as predições 'y_pred' com os valores reais 'y_teste'\n",
    "# Existem várias funções auxiliares no Scikit Learn para isso.\n",
    "\n",
    "# Aqui, imprimimos a precisão, revocação, f1-score e support (quantas instâncias têm a classe respectiva à linha\n",
    "# da tabela de métricas impressa)\n",
    "print(sklearn.metrics.classification_report(y_teste, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 11  5]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# É possível visualizar a matriz de confusão para as as predições. No caso do dataset iris, isso significa mostrar\n",
    "# quantas predições da classe 0 eram realmente classe 0, 1 ou 2,\n",
    "# quantas predições da classe 1 eram realmente classe 0, 1 ou 2, e\n",
    "# quantas predições da classe 2 eram realmente classe 0, 1 ou 2.\n",
    "print(sklearn.metrics.confusion_matrix(y_teste, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização\n",
    "Uma das fases mais importantes do processo de aprendizado de máquina, a *Otimização*, consiste em ajustar os parâmetros do modelo para conseguir melhores resultados.\n",
    "\n",
    "Uma das formas de se fazer isso é com a busca em grid, *gridsearch*. Escolhemos alguns parâmetros possíveis, e o gridsearch executa o nosso modelo com as diversas combinações possíveis, mantendo aquela com os melhores resultados.\n",
    "\n",
    "Repare que de fato ocorre uma melhora na classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros:\n",
      "{'penalty': 'l1', 'C': 100}\n",
      "\n",
      "Novas métricas:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      0.94      0.97        16\n",
      "          2       0.90      1.00      0.95         9\n",
      "\n",
      "avg / total       0.98      0.97      0.97        38\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Definimos aqui os dois parâmetros que serão combinados, 'penalty' e 'C', e os valores possíveis que cada um pode assumir\n",
    "parametros = {'penalty': ['l1', 'l2'], 'C':[1, 5, 10, 50, 100]}\n",
    "\n",
    "# Criamos um classificador tipo grid search, que irá buscar os melhores parâmetros com uma validação cruzada\n",
    "classificador = sklearn.linear_model.LogisticRegression()\n",
    "gridsearch = sklearn.grid_search.GridSearchCV(classificador, parametros)\n",
    "gridsearch.fit(X_treino, y_treino)\n",
    "\n",
    "print('Melhores parâmetros:')\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "# Fazemos as predições utilizando a melhor combinação de parâmetros do modelo\n",
    "y_pred = gridsearch.predict(X_teste)\n",
    "\n",
    "print('\\nNovas métricas:')\n",
    "print(sklearn.metrics.classification_report(y_teste, y_pred))\n",
    "print(sklearn.metrics.confusion_matrix(y_teste, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
